program: rlgames_train.py
method: grid  # oder 'random' für zufällige Auswahl der Parameterwerte
metric:
  name: reward
  goal: maximize
parameters:
  learning_rate:
    values: [0.001, 0.003, 0.005]
  tau:
    values: [0.005, 0.01, 0.02]
  actor_lr:
    values: [0.0001, 0.0003, 0.0005]
  gamma:
    values: [0.95, 0.99, 1.0]
  init_alpha:
    values: [0.5, 1.0, 1.5]
  alpha_lr:
    values: [0.0001, 0.0005, 0.001]
  critic_lr:
    values: [0.0001, 0.001, 0.01]
  critic_tau:
    values: [0.001, 0.005, 0.01]
  batch_size:
    values: [256, 512, 1024]
  kl_threshold:
    values: [0.007, 0.008, 0.009]
  num_seed_steps:
    values: [500, 1000, 1500]
  num_warmup_steps:
    values: [5000, 10000, 15000]
  replay_buffer_size:
    values: [1000000, 2000000, 3000000]
  network_units:
    values: ["[256, 256, 256]", "[512, 256, 128]", "[256, 128, 64]"]
